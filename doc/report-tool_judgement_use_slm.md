• 有効性レポート（実験日: 2026-02-11）

  モチベーション

  - ツール非対応や小型LLM（1B〜7B）でツール判断を安定化したいが、モデルを大きくすると遅
    い・高コスト。
  - 「軽量モデルで高速に大半を裁き、危ういときだけ重いモデルに頼る」ことで、応答品質とレイ
    テンシ/コストを両立したい。

  実験概要

  - 評価セット: 15問（計算5・検索5・NONE系5）。複数回実行で揺れ確認。
  - 比較モデル: qwen2.5-coder:1.5b-base, llama3.2:3b, phi3:3.8b, llama3.1:8b, qwen3:8b。
  - ルールミスマッチ（計算/検索キーワード・空query・列挙外）を検知し、必要時のみフォール
    バック。

  単体モデルの精度・速度（代表値）

  - qwen2.5-coder:1.5b-base … acc 0.60–0.80, avg_time ≈0.7–0.8s。高conf誤判定あり。
  - llama3.2:3b … acc 0.93–1.00, avg_time ≈1.0–1.1s。安定・高速。
  - phi3:3.8b … acc 1.00, avg_time ≈1.3s。軽量高精度のベスト。
  - llama3.1:8b … acc 1.00, avg_time ≈2.0–3.0s。重いが堅牢。
  - qwen3:8b … acc 1.00, avg_time ≈1.9–2.4s。8B系で最速クラス。

  信頼度の有用性

  - 1.5Bは誤判定でも conf≈0.9–1.0 を返すため、conf閾値はフォールバック判定に使いにくい。
  - 3B/3.8B/8Bも conf が0.5〜1.0に散り、単独の指標として弱い。

  ルールベース判定

  - 計算/検索キーワード、空query、列挙外で rule_mismatch / empty_query / bad_tool を付与。
  - 1.5Bの高信頼誤判定を拾い、フォールバックトリガとして有効。

  フォールバックパイプライン（実装済み）

  - 構成: primary=phi3:3.8b → fallback=qwen3:8b。
  - 実測: 15問で acc=1.00、平均レイテンシ 1.25–1.66s、フォールバック発動 0〜1回/15。
  - フォールバック発動時も合計3〜4秒程度で、全体平均を大きく押し上げない。

  結論

  - 小型1.5B単独は高conf誤判定が残るため実用には非推奨。
  - 3B/3.8B常用＋ルールミスマッチ時のみ8Bにエスカレーションで、精度1.00かつ平均≲1.5sを達成
    し、コスト・速度を両立。
  - フォールバック頻度が極低なので、まれに遅くなっても平均で充分償却できる。
